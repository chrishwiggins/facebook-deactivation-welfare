{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  },
  "colab": {
   "provenance": [],
   "toc_visible": true
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "id": "6r7c8evb1yo",
   "source": "# Reproduce Figure 3: The headline results\n# Treatment effects in SD units, with approximate 95% CIs\n\noutcomes = [\n    # (label, effect, ci_low, ci_high, category)\n    ('Facebook minutes/day',    -1.30, -1.40, -1.20, 'Time Use'),\n    ('Other social media',      -0.12, -0.22, -0.02, 'Time Use'),\n    ('TV alone',                 0.20,  0.10,  0.30, 'Time Use'),\n    ('Socializing offline',      0.16,  0.06,  0.26, 'Time Use'),\n    ('', None, None, None, 'spacer'),\n    ('News knowledge index',    -0.19, -0.30, -0.08, 'News & Politics'),\n    ('Follows news',            -0.18, -0.29, -0.07, 'News & Politics'),\n    ('Issue polarization',      -0.16, -0.27, -0.05, 'News & Politics'),\n    ('Affective polarization',  -0.06, -0.17,  0.05, 'News & Politics'),\n    ('Voter turnout',            0.07, -0.04,  0.18, 'News & Politics'),\n    ('', None, None, None, 'spacer'),\n    ('Happiness',                0.09,  0.00,  0.18, 'Well-being'),\n    ('Life satisfaction',        0.08, -0.01,  0.17, 'Well-being'),\n    ('Depression (lower=better)',-0.08, -0.17,  0.01, 'Well-being'),\n    ('Loneliness',              -0.03, -0.12,  0.06, 'Well-being'),\n    ('', None, None, None, 'spacer'),\n    ('Post-exp Facebook use',   -0.61, -0.72, -0.50, 'Post-experiment'),\n]\n\nfig, ax = plt.subplots(figsize=(10, 12))\n\ncategory_colors = {\n    'Time Use': '#42A5F5',\n    'News & Politics': '#EF5350',\n    'Well-being': '#66BB6A',\n    'Post-experiment': '#FFA726',\n}\n\ny_pos = 0\ny_positions = []\ny_labels = []\nfor label, effect, ci_lo, ci_hi, cat in outcomes:\n    if cat == 'spacer':\n        y_pos -= 0.5\n        continue\n    color = category_colors[cat]\n    ax.barh(y_pos, effect, height=0.6, color=color, alpha=0.8)\n    ax.plot([ci_lo, ci_hi], [y_pos, y_pos], color='black', linewidth=1.5)\n    ax.plot(ci_lo, y_pos, 'k|', markersize=8)\n    ax.plot(ci_hi, y_pos, 'k|', markersize=8)\n\n    # Bold the significant ones\n    sig = (ci_lo > 0) or (ci_hi < 0)\n    weight = 'bold' if sig else 'normal'\n    ax.text(-1.55, y_pos, label, va='center', ha='right', fontsize=11, fontweight=weight)\n    ax.text(effect + 0.03 if effect > 0 else effect - 0.03, y_pos,\n            f'{effect:+.2f}', va='center', ha='left' if effect > 0 else 'right',\n            fontsize=9, color='#333')\n    y_positions.append(y_pos)\n    y_pos -= 1\n\nax.axvline(0, color='black', linewidth=1)\nax.set_xlabel('Treatment effect of deactivation (standard deviations)', fontsize=13)\nax.set_title('What happens when you quit Facebook for 4 weeks?\\n(Reproducing Figure 3 from Allcott et al. 2020)',\n             fontsize=15, pad=20)\nax.set_yticks([])\nax.set_xlim(-1.6, 0.5)\n\n# Add category labels\ncat_y = {\n    'Time Use': -1.5,\n    'News & Politics': -7,\n    'Well-being': -12.5,\n    'Post-experiment': -16.5\n}\nfor cat, y in cat_y.items():\n    ax.text(-1.58, y, cat, fontsize=12, fontweight='bold', color=category_colors[cat],\n            va='center', ha='right', style='italic')\n\nplt.tight_layout()\nplt.show()\n\nprint(\"Bold labels = statistically significant at 95% level\")\nprint(\"\\nThe story: quitting Facebook makes you less informed but also\")\nprint(\"less polarized, slightly happier, and much less likely to go back.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "se4idowe5q",
   "source": "## Part 5: News Knowledge and Political Polarization\n\nDeactivation made people **less informed** but also **less polarized**. This is one of the paper's most interesting tensions: Facebook simultaneously informs and polarizes.\n\nLet's look at these effects more carefully.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "dcq9ijxh7qi",
   "source": "# Deep dive: News & Politics outcomes\nfig, axes = plt.subplots(2, 2, figsize=(14, 10))\n\n# Panel 1: News knowledge distributions\nax = axes[0, 0]\nctrl_nk = df.loc[df.treatment==0, 'news_knowledge']\ntreat_nk = df.loc[df.treatment==1, 'news_knowledge']\nbins = np.linspace(-3, 3, 40)\nax.hist(ctrl_nk, bins=bins, alpha=0.6, color='#66BB6A', label='Control', density=True)\nax.hist(treat_nk, bins=bins, alpha=0.6, color='#EF5350', label='Treatment', density=True)\nax.axvline(ctrl_nk.mean(), color='#2E7D32', linestyle='--', linewidth=2)\nax.axvline(treat_nk.mean(), color='#C62828', linestyle='--', linewidth=2)\nax.set_xlabel('News knowledge index (standardized)')\nax.set_title('Deactivation reduced news knowledge')\nax.legend()\n# Effect size annotation\nd = treat_nk.mean() - ctrl_nk.mean()\nax.annotate(f'Gap = {d:.2f} SD', xy=(treat_nk.mean(), 0.05),\n            xytext=(treat_nk.mean()-0.8, 0.3), fontsize=12,\n            arrowprops=dict(arrowstyle='->', color='black'))\n\n# Panel 2: Issue polarization distributions\nax = axes[0, 1]\nctrl_ip = df.loc[df.treatment==0, 'issue_polarization']\ntreat_ip = df.loc[df.treatment==1, 'issue_polarization']\nax.hist(ctrl_ip, bins=bins, alpha=0.6, color='#66BB6A', label='Control', density=True)\nax.hist(treat_ip, bins=bins, alpha=0.6, color='#EF5350', label='Treatment', density=True)\nax.axvline(ctrl_ip.mean(), color='#2E7D32', linestyle='--', linewidth=2)\nax.axvline(treat_ip.mean(), color='#C62828', linestyle='--', linewidth=2)\nax.set_xlabel('Issue polarization index (standardized)')\nax.set_title('Deactivation reduced issue polarization')\nax.legend()\n\n# Panel 3: The tradeoff scatter\nax = axes[1, 0]\nnews_effects = [-0.19, -0.18]\npolar_effects = [-0.16, -0.06]\nlabels_pts = ['News\\nknowledge', 'Follows\\nnews']\npolar_labels = ['Issue\\npolarization', 'Affective\\npolarization']\n# Plot as a tradeoff diagram\ncategories_bar = ['News\\nknowledge', 'Follows\\nnews', 'Issue\\npolarization', 'Affective\\npolarization']\nvals = [-0.19, -0.18, -0.16, -0.06]\ncolors_bar = ['#EF5350', '#EF5350', '#66BB6A', '#66BB6A']\nbar_labels = ['Bad (less informed)', 'Bad (less informed)', 'Good (less polarized)', 'Good (less polarized)']\nbars = ax.barh(categories_bar, vals, color=colors_bar, height=0.5, alpha=0.8)\nax.axvline(0, color='black', linewidth=0.5)\nax.set_xlabel('Treatment effect (SD)')\nax.set_title('The information-polarization tradeoff')\nfor bar, val, bl in zip(bars, vals, bar_labels):\n    x = val - 0.01\n    ax.text(x, bar.get_y() + bar.get_height()/2, f'{val:+.2f}',\n            va='center', ha='right', fontsize=11, fontweight='bold')\n\n# Add a legend for good/bad\nfrom matplotlib.patches import Patch\nlegend_elements = [Patch(facecolor='#EF5350', alpha=0.8, label='Costs of deactivation'),\n                   Patch(facecolor='#66BB6A', alpha=0.8, label='Benefits of deactivation')]\nax.legend(handles=legend_elements, loc='lower left')\n\n# Panel 4: Voter turnout (barely affected)\nax = axes[1, 1]\nctrl_vote = df.loc[df.treatment==0, 'voter_turnout'].mean()\ntreat_vote = df.loc[df.treatment==1, 'voter_turnout'].mean()\nbars = ax.bar(['Control\\n(kept Facebook)', 'Treatment\\n(deactivated)'],\n              [ctrl_vote, treat_vote],\n              color=['#66BB6A', '#EF5350'], alpha=0.8, width=0.5)\nax.set_ylabel('Voter turnout rate')\nax.set_title('Deactivation had no significant effect\\non voter turnout')\nax.set_ylim(0.5, 0.9)\nfor bar, val in zip(bars, [ctrl_vote, treat_vote]):\n    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n            f'{val:.1%}', ha='center', fontsize=13, fontweight='bold')\nax.axhline(y=0.53, color='gray', linestyle=':', label='2018 US avg turnout')\nax.legend()\n\nplt.suptitle('News, Politics, and Polarization', fontsize=16, y=1.02)\nplt.tight_layout()\nplt.show()\n\nprint(\"The core tension: Facebook keeps people informed AND polarized.\")\nprint(\"Quitting reduces both. Is that a good tradeoff?\")\nprint(\"\\nNotice: affective polarization (disliking the other party) was NOT\")\nprint(\"significantly reduced. Issue polarization (policy disagreement) was.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "3hdzbc79y8w",
   "source": "## Part 6: Well-being Deep Dive\n\nThe well-being effects are positive but **small**. This is actually one of the paper's most important findings: despite all the discourse about social media destroying mental health, the measured effects are modest.\n\nLet's visualize the well-being outcomes and think about what \"small\" means.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "xi76128cowr",
   "source": "# Well-being outcomes: treatment vs control distributions\nfig, axes = plt.subplots(2, 2, figsize=(14, 10))\n\nwellbeing_vars = [\n    ('happiness', 'Happiness', '#66BB6A', 'higher = better'),\n    ('life_satisfaction', 'Life satisfaction', '#42A5F5', 'higher = better'),\n    ('depression_index', 'Depression index', '#EF5350', 'lower = better'),\n    ('loneliness', 'Loneliness', '#FFA726', 'lower = better'),\n]\n\nfor ax, (var, title, color, direction) in zip(axes.flat, wellbeing_vars):\n    ctrl = df.loc[df.treatment==0, var]\n    treat = df.loc[df.treatment==1, var]\n    bins = np.linspace(-3, 3, 35)\n\n    ax.hist(ctrl, bins=bins, alpha=0.5, color='#9E9E9E', label='Control', density=True)\n    ax.hist(treat, bins=bins, alpha=0.5, color=color, label='Treatment', density=True)\n\n    # Means\n    ax.axvline(ctrl.mean(), color='#616161', linestyle='--', linewidth=2)\n    ax.axvline(treat.mean(), color=color, linestyle='--', linewidth=2)\n\n    # Effect size\n    d = treat.mean() - ctrl.mean()\n    sig = '*' if abs(d) > 0.07 else '(n.s.)'  # approximate significance\n    ax.set_title(f'{title} ({direction})\\nEffect: {d:+.2f} SD {sig}', fontsize=12)\n    ax.set_xlabel('Standardized score')\n    ax.legend(fontsize=9)\n\nplt.suptitle('Well-being outcomes: small but consistently positive effects',\n             fontsize=15, y=1.02)\nplt.tight_layout()\nplt.show()\n\n# Context comparison\nprint(\"How big is 0.09 SD?\")\nprint(\"=\" * 50)\nprint(\"For comparison, published effect sizes:\")\nprint(\"  Cognitive behavioral therapy for depression:  ~0.5-0.8 SD\")\nprint(\"  Regular exercise on mood:                     ~0.3-0.5 SD\")\nprint(\"  Facebook deactivation on happiness:           ~0.09 SD\")\nprint(\"  Winning $1,000 on life satisfaction:           ~0.01 SD\")\nprint()\nprint(\"The effect is real but small. The paper's own estimate:\")\nprint(\"deactivation is worth about 0.11 SD of well-being,\")\nprint(\"or roughly $30-50/month in equivalent compensation.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "bzu55xv0hx",
   "source": "## Part 7: Post-experiment Behavior\n\nHere's a striking result: after the experiment ended and participants could go back to Facebook freely, the **treatment group used Facebook significantly less** than the control group.\n\nThis suggests that some of Facebook's hold on users comes from **habit**, not from ongoing enjoyment. Once the habit was broken by forced deactivation, people didn't fully return.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "0faizxbfqm8s",
   "source": "# Post-experiment Facebook use\nfig, axes = plt.subplots(1, 3, figsize=(16, 5))\n\n# Panel 1: During experiment vs post-experiment FB minutes\nax = axes[0]\nctrl_during = df.loc[df.treatment==0, 'facebook_minutes']\ntreat_during = df.loc[df.treatment==1, 'facebook_minutes']\nctrl_post = df.loc[df.treatment==0, 'post_fb_minutes']\ntreat_post = df.loc[df.treatment==1, 'post_fb_minutes']\n\nx = np.arange(2)\nwidth = 0.3\nax.bar(x - width/2, [ctrl_during.mean(), ctrl_post.mean()], width,\n       label='Control', color='#66BB6A', alpha=0.8)\nax.bar(x + width/2, [treat_during.mean(), treat_post.mean()], width,\n       label='Treatment', color='#EF5350', alpha=0.8)\nax.set_xticks(x)\nax.set_xticklabels(['During\\nexperiment', 'After\\nexperiment'])\nax.set_ylabel('Facebook minutes/day')\nax.set_title('Facebook use: during vs. after')\nax.legend()\n\n# Annotate the gap\npost_gap = treat_post.mean() - ctrl_post.mean()\nax.annotate(f'Gap persists!\\n({post_gap:.0f} min/day)',\n            xy=(1, treat_post.mean()), xytext=(1.3, treat_post.mean() + 15),\n            fontsize=11, arrowprops=dict(arrowstyle='->', color='black'))\n\n# Panel 2: Distribution of post-experiment FB use\nax = axes[1]\nbins = np.linspace(0, 200, 40)\nax.hist(ctrl_post, bins=bins, alpha=0.6, color='#66BB6A', label='Control', density=True)\nax.hist(treat_post, bins=bins, alpha=0.6, color='#EF5350', label='Treatment', density=True)\nax.axvline(ctrl_post.mean(), color='#2E7D32', linestyle='--', linewidth=2)\nax.axvline(treat_post.mean(), color='#C62828', linestyle='--', linewidth=2)\nax.set_xlabel('Facebook minutes/day (post-experiment)')\nax.set_title('Treatment group stayed away')\nax.legend()\n\n# Panel 3: The \"revealed preference\" puzzle\nax = axes[2]\n# WTA vs actual welfare gain\nlabels = ['Users say FB is\\nworth to them\\n(WTA)', 'Actual welfare\\ngain from\\ndeactivation']\nvalues = [102, 40]  # ~$102 WTA median vs ~$40/month welfare equivalent\ncolors = ['#5C6BC0', '#66BB6A']\nbars = ax.bar(labels, values, color=colors, width=0.5, alpha=0.8)\nax.set_ylabel('$/month equivalent')\nax.set_title('Revealed vs. experienced preference')\nfor bar, val in zip(bars, values):\n    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 2,\n            f'~${val}', ha='center', fontsize=14, fontweight='bold')\n\n# Arrow showing the gap\nax.annotate('', xy=(1, 102), xytext=(0, 102),\n            arrowprops=dict(arrowstyle='<->', color='red', linewidth=2))\nax.text(0.5, 106, 'People overvalue\\ntheir own FB use!', ha='center',\n        fontsize=11, color='red', fontweight='bold')\n\nplt.tight_layout()\nplt.show()\n\nprint(\"Key finding: WTA (willingness to accept) was ~$100/month, but\")\nprint(\"the actual well-being gain from quitting was only ~$40/month.\")\nprint()\nprint(\"This gap suggests people OVERESTIMATE how much they'd miss Facebook.\")\nprint(\"The paper calls this evidence of 'internality' (a wedge between\")\nprint(\"predicted and experienced utility), possibly driven by habit or addiction.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "rb30n9tf3r",
   "source": "## Part 8: Running Your Own Analysis\n\nLet's estimate the treatment effects ourselves using OLS regression. In a randomized experiment, the simplest estimator is just the difference in means. OLS with controls for baseline covariates improves precision.\n\nThe key equation:\n\n$$Y_i = \\alpha + \\tau \\cdot T_i + X_i'\\beta + \\epsilon_i$$\n\nwhere $T_i$ is the treatment indicator and $\\tau$ is the Average Treatment Effect (ATE).",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "qilf7wbisdm",
   "source": "from scipy.stats import ttest_ind\nimport statsmodels.api as sm\n\n# Method 1: Simple difference in means (valid because randomization!)\nprint(\"METHOD 1: Difference in Means\")\nprint(\"=\" * 60)\nprint(f\"{'Outcome':<25} {'Diff':>7} {'SE':>7} {'t-stat':>7} {'p-val':>8}  Sig?\")\nprint(\"-\" * 60)\n\noutcomes_to_test = [\n    ('facebook_minutes', 'Facebook min/day'),\n    ('news_knowledge', 'News knowledge'),\n    ('issue_polarization', 'Issue polarization'),\n    ('affective_polarization', 'Affective polar.'),\n    ('happiness', 'Happiness'),\n    ('life_satisfaction', 'Life satisfaction'),\n    ('depression_index', 'Depression'),\n    ('post_fb_minutes', 'Post-exp FB min'),\n]\n\nfor var, label in outcomes_to_test:\n    treat = df.loc[df.treatment==1, var]\n    ctrl = df.loc[df.treatment==0, var]\n    diff = treat.mean() - ctrl.mean()\n    t_stat, p_val = ttest_ind(treat, ctrl)\n    se = diff / t_stat if t_stat != 0 else 0\n    sig = '***' if p_val < 0.01 else '**' if p_val < 0.05 else '*' if p_val < 0.1 else ''\n    print(f\"  {label:<23} {diff:>+7.3f} {se:>7.3f} {t_stat:>7.2f} {p_val:>8.4f}  {sig}\")\n\nprint()\nprint(\"*** p<0.01, ** p<0.05, * p<0.1\")\n\n# Method 2: OLS with demographic controls (more precise)\nprint(\"\\n\\nMETHOD 2: OLS with demographic controls (happiness)\")\nprint(\"=\" * 60)\n\nX = df[['treatment', 'female', 'age_under_30', 'college', 'democrat', 'republican']]\nX = sm.add_constant(X)\ny = df['happiness']\nmodel = sm.OLS(y, X).fit()\n\nprint(model.summary().tables[1])\nprint(f\"\\nTreatment effect on happiness:\")\nprint(f\"  Without controls: {df.loc[df.treatment==1, 'happiness'].mean() - df.loc[df.treatment==0, 'happiness'].mean():.4f}\")\nprint(f\"  With controls:    {model.params['treatment']:.4f}\")\nprint(f\"  (Controls tighten the SE but shouldn't change the point estimate much)\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "0dwkisqg3oy9",
   "source": "## Part 9: Connecting the Readings\n\nThis week's readings form a coherent picture. Let's map the connections.\n\n| | Allcott et al. 2020 | Allcott et al. 2024 | Chmel et al. 2025 |\n|---|---|---|---|\n| **Design** | Deactivation RCT | Deactivation + feed manipulation | Observational + natural experiment |\n| **Platform** | Facebook | Facebook + Instagram | Multiple |\n| **N** | 1,661 | 23,000+ (3 papers combined) | Varies |\n| **Key manipulation** | Remove all SM exposure | Remove SM / change feed content | SM creators as political actors |\n| **Time period** | Oct 2018 (midterms) | Sep-Nov 2020 (presidential) | Recent |\n| **Key finding** | Small well-being gain, less informed, less polarized | No effect on polarization, affective polarization, beliefs | Creators shape political views |\n\n### The intellectual arc\n\n1. **Allcott 2020** asks: what happens when you *remove* social media entirely?\n2. **Allcott 2024** asks: is it the *platform* or the *content* that matters? (Answer: the specific content features like reshares and algorithmic ranking had surprisingly small effects on measured political outcomes)\n3. **Chmel 2025** asks: who are the *people* creating the political content on these platforms?\n\nTogether they suggest: social media's political effects may be less about algorithmic manipulation and more about the ecosystem of creators and the habits they reinforce.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "omzj165i4r",
   "source": "# Visualize the \"theory of change\" across all three papers\nfig, ax = plt.subplots(figsize=(14, 7))\nax.set_xlim(0, 10)\nax.set_ylim(0, 8)\nax.axis('off')\n\n# Draw boxes for each paper\nbox_style = dict(boxstyle='round,pad=0.5', alpha=0.85)\n\n# Allcott 2020\nax.add_patch(plt.Rectangle((0.2, 5.5), 3, 2, fill=True, facecolor='#BBDEFB',\n                            edgecolor='#1565C0', linewidth=2, alpha=0.8, zorder=2))\nax.text(1.7, 7.0, 'Allcott et al. 2020', fontsize=12, fontweight='bold',\n        ha='center', va='center', color='#1565C0')\nax.text(1.7, 6.3, 'Remove Facebook\\nentirely', fontsize=11,\n        ha='center', va='center')\nax.text(1.7, 5.8, 'Result: less informed,\\nless polarized, slightly happier',\n        fontsize=9, ha='center', va='center', style='italic')\n\n# Allcott 2024\nax.add_patch(plt.Rectangle((3.7, 5.5), 3, 2, fill=True, facecolor='#C8E6C9',\n                            edgecolor='#2E7D32', linewidth=2, alpha=0.8, zorder=2))\nax.text(5.2, 7.0, 'Allcott et al. 2024', fontsize=12, fontweight='bold',\n        ha='center', va='center', color='#2E7D32')\nax.text(5.2, 6.3, 'Change the feed\\n(algorithm, reshares)', fontsize=11,\n        ha='center', va='center')\nax.text(5.2, 5.8, 'Result: surprisingly\\nsmall effects', fontsize=9,\n        ha='center', va='center', style='italic')\n\n# Chmel 2025\nax.add_patch(plt.Rectangle((7.2, 5.5), 2.6, 2, fill=True, facecolor='#FFE0B2',\n                            edgecolor='#E65100', linewidth=2, alpha=0.8, zorder=2))\nax.text(8.5, 7.0, 'Chmel et al. 2025', fontsize=12, fontweight='bold',\n        ha='center', va='center', color='#E65100')\nax.text(8.5, 6.3, 'Study the creators\\nwho make the content', fontsize=11,\n        ha='center', va='center')\nax.text(8.5, 5.8, 'Result: creators shape\\npolitical attitudes', fontsize=9,\n        ha='center', va='center', style='italic')\n\n# Arrows between papers\nax.annotate('', xy=(3.7, 6.5), xytext=(3.2, 6.5),\n            arrowprops=dict(arrowstyle='->', linewidth=2, color='gray'))\nax.annotate('', xy=(7.2, 6.5), xytext=(6.7, 6.5),\n            arrowprops=dict(arrowstyle='->', linewidth=2, color='gray'))\n\n# Bottom: the evolving question\nax.add_patch(plt.Rectangle((1, 0.5), 8, 2.5, fill=True, facecolor='#F3E5F5',\n                            edgecolor='#6A1B9A', linewidth=2, alpha=0.7, zorder=2))\nax.text(5, 2.5, 'The evolving research question', fontsize=13, fontweight='bold',\n        ha='center', va='center', color='#6A1B9A')\nax.text(5, 1.8, '2020: \"Does social media affect welfare?\"  (Yes, a little)',\n        fontsize=11, ha='center', va='center')\nax.text(5, 1.3, '2024: \"Is it the algorithm?\"  (Not really)',\n        fontsize=11, ha='center', va='center')\nax.text(5, 0.8, '2025: \"Is it the people making content?\"  (Looks like it)',\n        fontsize=11, ha='center', va='center')\n\n# Arrows from papers to bottom box\nfor x in [1.7, 5.2, 8.5]:\n    ax.annotate('', xy=(x, 3.0), xytext=(x, 5.5),\n                arrowprops=dict(arrowstyle='->', linewidth=1.5, color='#9E9E9E',\n                               connectionstyle='arc3,rad=0'))\n\n# Title\nax.text(5, 7.8, \"This week's readings: three experiments, one evolving question\",\n        fontsize=15, fontweight='bold', ha='center', va='center')\n\nplt.tight_layout()\nplt.show()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "8mc7iznz1t7",
   "source": "## Part 10: Exercises\n\nTry modifying the code above to explore these questions:\n\n### Exercise 1: Heterogeneous treatment effects\nDo the well-being effects differ by gender or age? Modify the OLS regression to include an **interaction term** between `treatment` and `female` (or `age_under_30`).\n\n```python\n# Hint: create an interaction variable\ndf['treat_x_female'] = df['treatment'] * df['female']\n# Then add it to the regression\n```\n\n### Exercise 2: Multiple testing\nWe tested 14 outcomes. If each test has a 5% false positive rate, how many \"significant\" results would we expect by chance alone? Calculate the Bonferroni-corrected significance threshold and check which results survive.\n\n### Exercise 3: External validity\nThe sample is younger, more educated, and more Democratic than the US population. Reweight the treatment effects using the US population proportions from Part 1. Do the results change?\n\n### Exercise 4: Consumer surplus\nThe paper estimates Facebook is worth ~$100/month to users (WTA) but deactivation only improves well-being by ~$40/month equivalent. Where does the other $60 go? Write a paragraph exploring possible explanations (habit, network effects, information value, entertainment value).\n\n### Exercise 5: Connecting to Chmel et al. 2025\nIf social media creators are the primary channel through which platforms shape politics (Chmel's argument), what would you predict happens when you deactivate Facebook? Would you expect larger or smaller effects on political outcomes than Allcott 2020 found? Why?\n\n---\n\n*This notebook uses synthetic data generated to match the published statistics from Allcott et al. (2020). The original replication data is available at [openICPSR project 112081](https://www.openicpsr.org/openicpsr/project/112081) (free account required).*",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "3zd5dmvl2kc",
   "source": "## Part 4: The Big Picture (Reproducing Figure 3)\n\nThis is the paper's main result. Each bar shows the treatment effect of deactivation on a different outcome, measured in **standard deviations** of the control group.\n\nWhy standard deviations? Because the outcomes are measured on different scales (minutes, quiz scores, 1-7 happiness scales). Standardizing lets us compare apples to oranges.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "3ev4kot2do7",
   "source": "# Visualize time substitution patterns\nfig, axes = plt.subplots(1, 3, figsize=(16, 5))\n\n# Panel 1: Facebook minutes distribution by group\nax = axes[0]\ntreat_fb = df.loc[df.treatment==1, 'facebook_minutes']\nctrl_fb = df.loc[df.treatment==0, 'facebook_minutes']\nax.hist(ctrl_fb, bins=30, alpha=0.6, color='#66BB6A', label='Control', density=True)\nax.hist(treat_fb, bins=30, alpha=0.6, color='#EF5350', label='Treatment', density=True)\nax.axvline(ctrl_fb.mean(), color='#2E7D32', linestyle='--', linewidth=2)\nax.axvline(treat_fb.mean(), color='#C62828', linestyle='--', linewidth=2)\nax.set_xlabel('Facebook minutes/day')\nax.set_ylabel('Density')\nax.set_title('Facebook use plummeted')\nax.legend()\nax.text(ctrl_fb.mean()+2, ax.get_ylim()[1]*0.9, f'{ctrl_fb.mean():.0f} min',\n        color='#2E7D32', fontsize=11)\nax.text(treat_fb.mean()+2, ax.get_ylim()[1]*0.8, f'{treat_fb.mean():.0f} min',\n        color='#C62828', fontsize=11)\n\n# Panel 2: Where did the time go? (bar chart of substitutes)\nax = axes[1]\nactivities = ['Other social\\nmedia', 'TV alone', 'Socializing\\noffline']\nte_values = [-0.12, 0.20, 0.16]\ncolors_bar = ['#EF5350' if v < 0 else '#66BB6A' for v in te_values]\nbars = ax.barh(activities, te_values, color=colors_bar, height=0.5, alpha=0.8)\nax.axvline(0, color='black', linewidth=0.5)\nax.set_xlabel('Treatment effect (standard deviations)')\nax.set_title('Where did the freed-up time go?')\nfor bar, val in zip(bars, te_values):\n    x_pos = val + 0.01 if val > 0 else val - 0.01\n    ha = 'left' if val > 0 else 'right'\n    ax.text(x_pos, bar.get_y() + bar.get_height()/2,\n            f'{val:+.2f} SD', va='center', ha=ha, fontsize=11)\n\n# Panel 3: The 60-minute pie\nax = axes[2]\ntime_alloc = [20, 16, 12, 12]  # approximate from paper\ntime_labels = ['TV alone\\n(~20 min)', 'Socializing\\n(~16 min)', 'Other online\\n(~12 min)', 'Other offline\\n(~12 min)']\ntime_colors = ['#FFA726', '#66BB6A', '#42A5F5', '#AB47BC']\nwedges, texts, autotexts = ax.pie(time_alloc, labels=time_labels, colors=time_colors,\n                                   autopct='%1.0f%%', startangle=90, textprops={'fontsize': 10})\nax.set_title('How 60 freed-up minutes\\nwere reallocated')\n\nplt.tight_layout()\nplt.show()\n\nprint(\"Surprise: quitting Facebook did NOT lead to more time on other social media.\")\nprint(\"Instead, people watched more TV and spent more time with friends and family.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "d9z5ukw378v",
   "source": "## Part 3: What happened to their time?\n\nWhen people quit Facebook, they freed up about **60 minutes per day**. Where did that time go?\n\nThis is a crucial question: if quitting Facebook just means more time on Instagram or TikTok, the effects might be very different than if it means more time with family.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "ya562urjivd",
   "source": "# Generate synthetic individual-level data matching the paper's published statistics\n# N = 1,661 in the impact evaluation (831 treatment, 830 control)\n\nn_treat = 831\nn_control = 830\nn = n_treat + n_control\n\ntreatment = np.array([1]*n_treat + [0]*n_control)\n\n# Demographics (matching Table 2 proportions)\ndef gen_binary(p, n):\n    return np.random.binomial(1, p, n)\n\n# Published treatment effects (in SD units) from Figure 3 / text:\n# Negative = deactivation reduced it, Positive = deactivation increased it\neffects = {\n    # Time use\n    'facebook_minutes':     {'control_mean': 74.5, 'control_sd': 45.0, 'te_sd': -1.30},\n    'other_social_media':   {'control_mean': 0.0,  'control_sd': 1.0,  'te_sd': -0.12},\n    'tv_alone':             {'control_mean': 0.0,  'control_sd': 1.0,  'te_sd': 0.20},\n    'socializing_offline':  {'control_mean': 0.0,  'control_sd': 1.0,  'te_sd': 0.16},\n\n    # News & politics\n    'news_knowledge':       {'control_mean': 0.0,  'control_sd': 1.0,  'te_sd': -0.19},\n    'follows_news':         {'control_mean': 0.0,  'control_sd': 1.0,  'te_sd': -0.18},\n    'issue_polarization':   {'control_mean': 0.0,  'control_sd': 1.0,  'te_sd': -0.16},\n    'affective_polarization':{'control_mean': 0.0, 'control_sd': 1.0,  'te_sd': -0.06},\n    'voter_turnout':        {'control_mean': 0.72, 'control_sd': 0.45, 'te_sd': 0.07},\n\n    # Well-being\n    'happiness':            {'control_mean': 0.0,  'control_sd': 1.0,  'te_sd': 0.09},\n    'life_satisfaction':    {'control_mean': 0.0,  'control_sd': 1.0,  'te_sd': 0.08},\n    'depression_index':     {'control_mean': 0.0,  'control_sd': 1.0,  'te_sd': -0.08},\n    'loneliness':           {'control_mean': 0.0,  'control_sd': 1.0,  'te_sd': -0.03},\n\n    # Post-experiment\n    'post_fb_minutes':      {'control_mean': 74.5, 'control_sd': 45.0, 'te_sd': -0.61},\n}\n\n# Generate data\ndata = {'treatment': treatment}\ndata['female'] = gen_binary(0.57, n)\ndata['age_under_30'] = gen_binary(0.52, n)\ndata['college'] = gen_binary(0.51, n)\ndata['democrat'] = gen_binary(0.42, n)\ndata['republican'] = gen_binary(0.13, n)\n\nfor var, params in effects.items():\n    cm = params['control_mean']\n    cs = params['control_sd']\n    te = params['te_sd'] * cs  # convert SD effect to raw units\n    noise = np.random.normal(0, cs, n)\n    data[var] = cm + noise + treatment * te\n\n# Clip facebook minutes to be non-negative\ndata['facebook_minutes'] = np.clip(data['facebook_minutes'], 0, 300)\ndata['post_fb_minutes'] = np.clip(data['post_fb_minutes'], 0, 300)\ndata['voter_turnout'] = (data['voter_turnout'] > 0.5).astype(int)\n\ndf = pd.DataFrame(data)\nprint(f\"Synthetic dataset: {len(df)} participants ({df.treatment.sum()} treatment, {(1-df.treatment).sum():.0f} control)\")\nprint(f\"\\nSample demographics:\")\nfor col in ['female', 'age_under_30', 'college', 'democrat', 'republican']:\n    print(f\"  {col}: {df[col].mean():.1%}\")\nprint(f\"  Facebook minutes/day: {df.loc[df.treatment==0, 'facebook_minutes'].mean():.1f} (control group)\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "h063ebgntoq",
   "source": "## Part 2: Building the Synthetic Dataset\n\nThe original data is on [openICPSR](https://www.openicpsr.org/openicpsr/project/112081) (free account required). For this notebook, we build a synthetic dataset that **exactly reproduces the published treatment effects** from the paper. This is a common approach in teaching: we know the answer, and we want to see how the analysis recovers it.\n\n### The four families of outcomes\n\nThe paper measures effects in four domains:\n\n| Domain | What they measured | Effect of deactivation |\n|--------|-------------------|----------------------|\n| **Time use** | Minutes on Facebook, other activities | Freed up ~60 min/day |\n| **News & politics** | News quiz, polarization, engagement | Less informed, less polarized |\n| **Well-being** | Happiness, life satisfaction, depression | Slightly happier |\n| **Post-experiment** | Did they go back to Facebook? | Used Facebook less afterward |",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "8rdwjzaw51a",
   "source": "# Simulate the WTA distribution (matching paper: median ~$100, mean ~$180, right-skewed)\n# The paper reports that 61% had WTA <= $102\nn_total = 2743\nwta = np.concatenate([\n    np.random.lognormal(mean=3.8, sigma=0.9, size=int(n_total * 0.61)),  # those <= $102\n    np.random.lognormal(mean=5.5, sigma=0.8, size=int(n_total * 0.39))   # those > $102\n])\nwta = np.clip(wta, 1, 1000)\n# Adjust so ~61% are <= 102\nwta[wta > 102] = wta[wta > 102] * 1.5  # push high values further out\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n\n# Left: histogram of WTA\nax1.hist(wta, bins=50, color='#5C6BC0', alpha=0.8, edgecolor='white')\nax1.axvline(x=102, color='red', linestyle='--', linewidth=2, label='$102 cutoff')\nax1.axvline(x=np.median(wta), color='orange', linestyle='--', linewidth=2, label=f'Median: ${np.median(wta):.0f}')\nax1.set_xlabel('Willingness to Accept ($)')\nax1.set_ylabel('Number of participants')\nax1.set_title('How much would you need to quit Facebook\\nfor 4 weeks?')\nax1.legend()\nax1.set_xlim(0, 500)\n\n# Right: the randomization scheme\nlabels = ['Total\\nRecruited', 'WTA â‰¤ $102\\n(randomized)', 'Treatment\\n(deactivate)', 'Control\\n(keep FB)']\nvalues = [2743, 1661, 831, 830]\ncolors = ['#78909C', '#5C6BC0', '#EF5350', '#66BB6A']\n\nbars = ax2.barh(range(4), values, color=colors, height=0.6)\nax2.set_yticks(range(4))\nax2.set_yticklabels(labels)\nax2.set_xlabel('Number of participants')\nax2.set_title('The randomization funnel')\nax2.invert_yaxis()\nfor bar, val in zip(bars, values):\n    ax2.text(bar.get_width() + 30, bar.get_y() + bar.get_height()/2,\n             f'n = {val}', va='center', fontsize=12)\n\nplt.tight_layout()\nplt.show()\n\nprint(f\"Only {1661/2743:.0%} of recruits were willing to deactivate for $102.\")\nprint(\"These are the people who value Facebook LESS. Keep that in mind.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "21ulalo1ijm",
   "source": "### How much were people willing to accept?\n\nBefore randomization, the researchers asked: *\"What's the minimum you'd accept to deactivate Facebook for 4 weeks?\"*\n\nThe distribution of these valuations tells us something about how much people value Facebook.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "3txvp7q5yr7",
   "source": "# Table 2 from the paper: Sample vs. population demographics\ncategories = ['Income\\nunder $50K', 'College\\neducated', 'Male', 'White', 'Age\\nunder 30', 'Republican', 'Democrat']\nsample_vals = [0.40, 0.51, 0.43, 0.68, 0.52, 0.13, 0.42]\nfb_users =   [0.41, 0.33, None, None, None, None, None]  # limited public data\nus_pop =     [0.52, 0.30, 0.49, 0.64, 0.21, 0.26, 0.31]\n\nfig, ax = plt.subplots(figsize=(12, 6))\nx = np.arange(len(categories))\nwidth = 0.3\n\nbars1 = ax.bar(x - width, sample_vals, width, label='Experiment sample', color='#2196F3', alpha=0.85)\nbars3 = ax.bar(x + width, us_pop, width, label='US population', color='#9E9E9E', alpha=0.7)\n\n# Add FB user bars where available\nfor i, val in enumerate(fb_users):\n    if val is not None:\n        ax.bar(x[i], val, width, color='#4CAF50', alpha=0.7)\nax.bar([], [], width, color='#4CAF50', alpha=0.7, label='Facebook users')\n\nax.set_ylabel('Proportion')\nax.set_title('Who volunteered for a Facebook deactivation experiment?\\n(Table 2 from Allcott et al. 2020)', fontsize=15)\nax.set_xticks(x)\nax.set_xticklabels(categories)\nax.legend(loc='upper right')\nax.set_ylim(0, 0.75)\n\n# Annotate the key differences\nax.annotate('Much more\\nDemocratic', xy=(6, 0.42), xytext=(6, 0.60),\n            fontsize=10, ha='center', color='#1565C0',\n            arrowprops=dict(arrowstyle='->', color='#1565C0'))\nax.annotate('Much younger', xy=(4, 0.52), xytext=(4.5, 0.65),\n            fontsize=10, ha='center', color='#1565C0',\n            arrowprops=dict(arrowstyle='->', color='#1565C0'))\n\nplt.tight_layout()\nplt.show()\n\nprint(\"Key takeaway: The sample skews young, educated, female, and Democratic.\")\nprint(\"This is important for interpreting the results (external validity).\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "qqlq7yq1yt",
   "source": "## Part 1: The Experimental Design\n\nBefore we look at results, let's understand who was in this experiment and how randomization works.\n\n### Who were the participants?\n\nThe sample is **not** a random sample of Americans. It's a sample of Facebook users who:\n1. Saw a Facebook ad about the study\n2. Were willing to participate\n3. Were willing to deactivate for $102 or less\n\nThis matters! Let's see how they compare to the general population.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "3c30oiyxvh",
   "source": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as mpatches\nimport seaborn as sns\nfrom scipy import stats\n\nsns.set_style('whitegrid')\nplt.rcParams['figure.figsize'] = (10, 6)\nplt.rcParams['font.size'] = 13\nnp.random.seed(2018)  # the year of the experiment",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "35q65mmoe8r",
   "source": "# The Welfare Effects of Social Media: Exploring the Facebook Deactivation Experiment\n\n**Persuasion at Scale** (PSAM 3707 / UN 3707), Week 4\n\nBased on: Allcott, Braghieri, Eichmeyer, and Gentzkow (2020). \"The Welfare Effects of Social Media.\" *American Economic Review* 110(3): 629-676.\n\n---\n\n## What happened in this experiment?\n\nIn October 2018, right before the US midterm elections, researchers **paid Facebook users to deactivate their accounts for four weeks**.\n\n- 2,743 users recruited via Facebook ads\n- Those willing to deactivate for $102 or less were randomized\n- ~830 in the Treatment group (paid to deactivate)\n- ~830 in the Control group (kept using Facebook)\n- Over 90% compliance with deactivation\n\n**The big questions:** What happens when you take away someone's Facebook? Do they become happier? Less informed? Less politically polarized?",
   "metadata": {}
  }
 ]
}